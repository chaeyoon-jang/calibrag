python -m experiments.make_decision_vllm --data_dir "./logs/calibrag_binary_gold_bm25_5/calibrag/test-calibrag" --batch_size 32 --max_new_tokens 50 --model_name "meta-llama/Meta-Llama-3.1-8B-Instruct" --inference False --log_dir ./logs/decision_bm25_5
python -m experiments.make_decision_vllm --data_dir "./logs/calibrag_binary_gold_bm25_10/calibrag/test-calibrag" --batch_size 32 --max_new_tokens 50 --model_name "meta-llama/Meta-Llama-3.1-8B-Instruct" --inference False --log_dir ./logs/decision_bm25_10
python -m experiments.make_decision_vllm --data_dir "./logs/calibrag_binary_gold_contriever_5/calibrag/test-calibrag" --batch_size 32 --max_new_tokens 50 --model_name "meta-llama/Meta-Llama-3.1-8B-Instruct" --inference False --log_dir ./logs/decision_contriever_5
python -m experiments.make_decision_vllm --data_dir "./logs/calibrag_binary_gold_contriever_10/calibrag/test-calibrag" --batch_size 32 --max_new_tokens 50 --model_name "meta-llama/Meta-Llama-3.1-8B-Instruct" --inference False --log_dir ./logs/decision_contriever_10
python -m experiments.make_decision_vllm --data_dir "./logs/calibrag_binary_gold_contriever_40_s/calibrag/test-calibrag" --batch_size 32 --max_new_tokens 50 --model_name "meta-llama/Meta-Llama-3.1-8B-Instruct" --inference False --log_dir ./logs/decision_contriever_40_s